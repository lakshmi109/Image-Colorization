{"cells":[{"cell_type":"code","execution_count":20,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-27T19:16:04.801313Z","iopub.status.busy":"2024-04-27T19:16:04.800815Z","iopub.status.idle":"2024-04-27T19:16:05.518494Z","shell.execute_reply":"2024-04-27T19:16:05.517767Z","shell.execute_reply.started":"2024-04-27T19:16:04.801286Z"},"trusted":true},"outputs":[],"source":["import cv2\n","from skimage import feature\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from skimage.feature import hog\n","from skimage.color import rgb2lab\n","import os\n","import cv2\n","import numpy as np\n","from skimage.feature import hog"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-04-27T19:16:05.520680Z","iopub.status.busy":"2024-04-27T19:16:05.520084Z","iopub.status.idle":"2024-04-27T19:16:05.527815Z","shell.execute_reply":"2024-04-27T19:16:05.526395Z","shell.execute_reply.started":"2024-04-27T19:16:05.520650Z"},"trusted":true},"outputs":[],"source":["\n","class LocalBinaryPatterns:\n","    def __init__(self, numPoints, radius):\n","        self.numPoints = numPoints\n","        self.radius = radius\n","    def describe(self, image, eps=1e-7):\n","        lbp = feature.local_binary_pattern(image, self.numPoints,\n","            self.radius, method=\"uniform\")\n","        (hist, _) = np.histogram(lbp.ravel(),\n","            bins=np.arange(0, self.numPoints + 3),\n","            range=(0, self.numPoints + 2))\n","        hist = hist.astype(\"float\")\n","        hist /= (hist.sum() + eps)\n","        return hist"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-04-27T20:09:43.547572Z","iopub.status.busy":"2024-04-27T20:09:43.547197Z","iopub.status.idle":"2024-04-27T20:09:43.579882Z","shell.execute_reply":"2024-04-27T20:09:43.578207Z","shell.execute_reply.started":"2024-04-27T20:09:43.547543Z"},"trusted":true},"outputs":[],"source":["class Colorize:\n","    def __init__(self):\n","        self.threshold=None\n","        self.dicto = {}\n","        self.example = 0\n","    def feature_extractor(self, img_L, img_A, img_B):\n","        # Check if the input image has the correct dimensions\n","        if img_L.shape[0] <= 8 or img_L.shape[1] <= 8:\n","            # Resize the image to meet the minimum size requirements for HOG computation\n","            img_L_resized = cv2.resize(img_L, (8, 8))  # Adjust the size as needed\n","            img_A_resized = cv2.resize(img_A, (8, 8))  # Resize corresponding channels if needed\n","            img_B_resized = cv2.resize(img_B, (8, 8))\n","            \n","            # Proceed with feature extraction on the resized image\n","            hog_features, hog_image = hog(img_L_resized, orientations=9, pixels_per_cell=(8, 8),\n","                                            cells_per_block=(2, 2), visualize=True, block_norm='L2-Hys')\n","\n","            # local binary pattern\n","            lbp = LocalBinaryPatterns(24,8)\n","            lbp_features = lbp.describe(img_L_resized)\n","\n","            # # histogram of oriented gradients\n","            # hist = cv2.calcHist([img_L_resized],[0],None,[256],[0,256]).flatten()\n","            # print(hist.shape)\n","\n","            features = tuple(np.concatenate((hog_features, lbp_features)))\n","            self.dicto[features] = np.array([np.mean(img_A_resized), np.mean(img_B_resized)])\n","            self.example = features\n","            return features\n","\n","\n","        else:\n","            # Proceed with feature extraction on the original image\n","            hog_features, hog_image = hog(img_L, orientations=9, pixels_per_cell=(8, 8),\n","                                            cells_per_block=(2, 2), visualize=True, block_norm='L2-Hys')\n","\n","            # local binary pattern\n","            lbp = LocalBinaryPatterns(24,8)\n","            lbp_features = lbp.describe(img_L)\n","\n","            # # histogram of oriented gradients\n","            # hist = cv2.calcHist([img_L],[0],None,[256],[0,256]).flatten()\n","            # print(hist.shape)\n","\n","            features = tuple(np.concatenate((hog_features, lbp_features)))\n","            self.dicto[features] = np.array([np.mean(img_A), np.mean(img_B)])\n","            \n","            \n","            return features\n","\n","    \n","    def feature_extractor_target_image(self, target_img_L, target_img_A, target_img_B):\n","        # Check if the input image has the correct dimensions\n","        if target_img_L.shape[0] < 8 or target_img_L.shape[1] < 8:\n","            # Resize the image to meet the minimum size requirements for HOG computation\n","            target_img_L_resized = cv2.resize(target_img_L, (8, 8))  # Adjust the size as needed\n","            target_img_A_resized = cv2.resize(target_img_A, (8, 8))  # Resize corresponding channels if needed\n","            target_img_B_resized = cv2.resize(target_img_B, (8, 8))\n","\n","            # Proceed with feature extraction on the resized image\n","            hog_features, hog_image = hog(target_img_L_resized, orientations=9, pixels_per_cell=(8, 8),\n","                                            cells_per_block=(2, 2), visualize=True, block_norm='L2-Hys')\n","\n","            # Local binary pattern\n","            lbp = LocalBinaryPatterns(24, 8)\n","            lbp_features = lbp.describe(target_img_L_resized)\n","\n","            # # Histogram of oriented gradients\n","            # hist = cv2.calcHist([target_img_L_resized], [0], None, [256], [0, 256]).flatten()\n","\n","            features = np.concatenate((hog_features, lbp_features))\n","            return features\n","\n","        else:\n","            target_img_L_resized = cv2.resize(target_img_L, (8, 8))\n","            # Proceed with feature extraction on the original image\n","            hog_features, hog_image = hog(target_img_L_resized, orientations=9, pixels_per_cell=(8, 8),\n","                                            cells_per_block=(2, 2), visualize=True, block_norm='L2-Hys')\n","\n","            # Local binary pattern\n","            lbp = LocalBinaryPatterns(24, 8)\n","            lbp_features = lbp.describe(target_img_L)\n","\n","            # # Histogram of oriented gradients\n","            # hist = cv2.calcHist([target_img_L], [0], None, [256], [0, 256]).flatten()\n","\n","            features = np.concatenate((hog_features, lbp_features))\n","            return features\n","\n","    \n","    def train(self,directory_path):\n","        window_size = 4\n","        for i,filename in enumerate(os.listdir(directory_path)):\n","            if i < 10:\n","                img_path = os.path.join(directory_path, filename)\n","                img = cv2.imread(img_path)\n","                img = cv2.resize(img, (64, 64))\n","                lab_image = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n","                L_channel = lab_image[:, :, 0]\n","\n","                    \n","                    \n","                print(L_channel.shape[0], L_channel.shape[1])\n","                for i in range(L_channel.shape[0] - window_size + 1):\n","                    for j in range(L_channel.shape[1] - window_size + 1):\n","                        window = L_channel[i:i+window_size, j:j+window_size]\n","                        window_A = lab_image[i:i+window_size, j:j+window_size, 1]\n","                        window_B = lab_image[i:i+window_size, j:j+window_size, 2]\n","\n","                        features = self.feature_extractor(window, window_A, window_B)\n","\n","                print(len(self.dicto))\n","\n","    \n","\n","\n","    def colurize(self, target_image):\n","        window_size = 4\n","        target_image = cv2.resize(target_image, (64, 64))\n","        target_lab_image = cv2.cvtColor(target_image, cv2.COLOR_BGR2LAB)\n","\n","        target_L_channel = target_lab_image[:, :, 0]\n","\n","        for i in range(target_L_channel.shape[0] - window_size + 1):\n","            for j in range(target_L_channel.shape[1] - window_size + 1):\n","                window = target_L_channel[i:i+window_size, j:j+window_size]\n","                window_A = target_lab_image[i:i+window_size, j:j+window_size, 1]\n","                window_B = target_lab_image[i:i+window_size, j:j+window_size, 2]\n","\n","                features = self.feature_extractor_target_image(window, window_A, window_B)\n","                min_distance = 1000000000\n","                color_A, color_B = self.dicto[self.example]\n","\n","                for key in self.dicto.keys():\n","                    distance = np.linalg.norm(features-key)\n","                    if distance < min_distance:\n","                        min_distance = distance\n","                        color_A, color_B = self.dicto[key]\n","                target_lab_image[i:i+window_size, j:j+window_size, 1] = color_A\n","                target_lab_image[i:i+window_size, j:j+window_size, 2] = color_B\n","\n","\n","        # Convert the image back to BGR color space\n","        target_image = cv2.cvtColor(target_lab_image, cv2.COLOR_LAB2BGR)\n","        \n","        return target_image\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-27T20:09:44.536814Z","iopub.status.busy":"2024-04-27T20:09:44.536500Z"},"trusted":true},"outputs":[],"source":["\n","\n","target_image = cv2.imread('test.jpg')\n","\n","\n","\n","colorizer = Colorize()\n","\n","colorizer.train(\"C:/Users/azhar/Downloads/Similar mountains/Similar mountains\")\n","\n","colorized_image = colorizer.colurize(target_image)\n","\n","\n","plt.figure(figsize=(15, 5))\n","\n","# plt.subplot(1, 3, 1)\n","# plt.title('Input Image')\n","# plt.imshow(cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB))\n","# plt.axis('off')\n","\n","plt.subplot(1, 2, 1)\n","plt.title('Target Image')\n","plt.imshow(cv2.cvtColor(target_image, cv2.COLOR_BGR2RGB))\n","plt.axis('off')\n","\n","plt.subplot(1, 2, 2)\n","plt.title('Colorized Image')\n","plt.imshow(cv2.cvtColor(colorized_image, cv2.COLOR_BGR2RGB))\n","plt.axis('off')\n","\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize=(15, 5))\n","\n","plt.subplot(1, 3, 1)\n","plt.title('Input Image')\n","plt.imshow(cv2.cvtColor(target_image, cv2.COLOR_BGR2GRAY),cmap=\"gray\")\n","plt.axis('off')\n","\n","plt.subplot(1, 3, 2)\n","plt.title('Orignal Image')\n","plt.imshow(cv2.cvtColor(target_image, cv2.COLOR_BGR2RGB))\n","plt.axis('off')\n","\n","plt.subplot(1, 3, 3)\n","plt.title('Colorized Image')\n","plt.imshow(cv2.cvtColor(colorized_image, cv2.COLOR_BGR2RGB))\n","plt.axis('off')\n","\n","plt.show()"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":111880,"sourceId":269359,"sourceType":"datasetVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7"}},"nbformat":4,"nbformat_minor":4}
